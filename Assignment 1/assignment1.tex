%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CMPT 435
% Lab Zero
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from: http://www.LaTeXTemplates.com
% Original author: % Frits Wenneker (http://www.howtotex.com)
% License: CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% Modified by Alan G. Labouseur  - alan@labouseur.com, and Patrick Tyler - Patrick.Tyler1@marist.edu
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[letterpaper, 10pt]{article} 

\usepackage[english]{babel} % English language/hyphenation
\usepackage{graphicx}
\usepackage[lined,linesnumbered,commentsnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\usepackage{lastpage}
\usepackage{url}
\usepackage{xcolor}
\usepackage{titlesec}

% Stolen from https://www.overleaf.com/learn/latex/Code_listing 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle, language=c++}


\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{page \thepage\ of \pageref{LastPage}} % Page numbering for center footer
\fancyfoot[R]{}

\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
   \normalfont \normalsize 
   \textsc{CMPT 435 - Fall 2023 - Dr. Labouseur} \\[10pt] % Header stuff.
   \horrule{0.5pt} \\[0.25cm] 	% Top horizontal rule
   \huge Assignment One -- \LaTeX ~Data\\     	    % Assignment title
   \horrule{0.5pt} \\[0.25cm] 	% Bottom horizontal rule
}

\author{Patrick Tyler \\ \normalsize Patrick.Tyler1@marist.edu}

\date{\normalsize\today} 	% Today's date.

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%   CONTENT SECTION
%----------------------------------------------------------------------------------------

% - -- -  - -- -  - -- -  -
\section{Nodes, Stacks, \& Queues}
\subsection{Making a Node}
A node needs to contain the data it stores and reference(s) to another node.
In this case, just a single reference to a next node is needed because the nodes will only be singly linked.
A node struct could be used to implement this which wraps a piece of data with a reference to the next Node.
A node is a building block for many different algorithms and structures; 
therefore, this node structure should be generic enough to easily create a node storing any type of data.
\lstinputlisting[linerange={27-32}, firstnumber=27]{main.cpp}
\subsection{Stacks \& Queues}
Nodes can link together to form stacks and queues.
Stacks and queues in programming should be intuitive as stacks (much like a stack of papers)
are last in first out (LIFO) while queues (much like a line of people waiting for something) are first in first out (FIFO).\\
\newline
Well structured stack and queue classes encapsulate their node structure only exposing their 
respective functionality to add and get data. Both stacks and queues should have methods to check if the are empty, add data, and remove data.
The interface for stacks minimally follows: push() and pop(). The interface for queues minimally follows:
queue() and enqueue(). It should be obvious what each method does. The methods ideally all run
in constant time. \\
\newline
The stack class will need to have a pointer to the head (the top of the stack) to implement its interface.\\
\textbf{Push action:}
\begin{enumerate}
    \item Takes in a piece of data and creates a new node.
    \item Sets the new node to this head.
    \item Sets the new node's next value to the previous head (if there was one).
\end{enumerate}
\lstinputlisting[linerange={98-102}, firstnumber=98]{main.cpp}
\textbf{Pop action:}
\begin{enumerate}
    \item Make the new head the current head's next attribute.
    \item Return the value of the now old head node.
\end{enumerate}
\lstinputlisting[linerange={105-114}, firstnumber=105]{main.cpp}
\textbf{isEmpty action:}
\begin{enumerate}
    \item Returns if the head is currently points to a node.
\end{enumerate}
\hrule
\vspace{.25cm}
Why are stacks often the life of the party? - \textit{They get it popping.}\\
\hrule
\vspace{1cm}
The queue class will need to have a pointer to the first (start of the line) and the last (end of the line) node
to implement its interface in constant time. It is possible to only have a pointer to the first node and then traverse
the queue to obtain the last, but the trade off to store an additional pointer to the last element is almost worth it because
it saves queues from having to execute a linear time complexity operation when enqueuing.\\
\newpage
\textbf{Enqueue action:}
\begin{enumerate}
    \item Takes in a piece of data and creates a new node.
    \item Sets the new node to the equal to the tail.
    \item Only if there was no head node, sets the new node equal to the head.
    \item Sets the previous tail's next value to the new node (if there was one).
\end{enumerate}
\lstinputlisting[linerange={47-62}, firstnumber=47]{main.cpp}
\textbf{Dequeue action:}
\begin{enumerate}
    \item Set the first to the current first's next attribute.
    \item Return the value of now the old head node.
\end{enumerate}
\lstinputlisting[linerange={66-79}, firstnumber=66]{main.cpp}
\textbf{isEmpty action:}
\begin{enumerate}
    \item Returns if the head is currently points to a node.
\end{enumerate}
\newpage
\hrule
% Java syntax makes this joke better
\begin{lstlisting}[language=Java]
public class Queue<T> {
...
\end{lstlisting}
Guy: \textit{Hey girl, are you my generically typed queue declaration?}\\
Girl: \textit{What?}\\
Guy: \textit{Because you're a Queue\textless T\textgreater}.\\
Girl: \textit{...}\\
\hrule
\vspace{1cm}
\subsection{A Simple Stack \& Queue Use Case}
A palindrome is phrase that is the same forward and backwards often only including
alphanumeric characters and excluding casing.  "Race car" is a palindrome because the letters read the same
front to back and back to front.

\[R_0 a_1 c_2 e_3 \ c_4 a_5 r_6 == r_6 a_5 c_4 \ e_3 c_2 a_1 R_0\]
\noindent
This applies to stacks and queues as if the letters of race car were pushed to a stack
as well as enqueued to a queue, comparing, in order, the dequeued elements with the popped elements
renders all equal comparisons. In other words, if any of these comparisons are false, then then the phrase is not
a palindrome. Implementation of this in code is left as an exercise to the reader.

\section{Sorting}
\subsection{Introduction}
An array of data (say n with length x) is said to be sorted when comparable elements are arranged in an order
such that:
\[n_0 <= n_1 <= n_2 <= n_3 \dots <= n_{x-1} \]
\[or\]
\[n_0 >= n_1 >= n_2 >= n_3 \dots >= n_{x-1}\]
For future algorithms such as binary search, this relationship is foundational.
\subsection{The "Opposite" of Sorted}
Conceptually, the opposite of a sorted array is one in which the elements are
randomly positioned. This does not mean the array is not sorted, just that the elements
are placed randomly. One of the most intuitive random shuffling algorithms is the Fisher Yates Shuffle.
It iterates through each index of the array picking a random index of out the current index and all indexes
not yet iterated through and swaps those indices.
\lstinputlisting[linerange={225-240}, firstnumber=225]{main.cpp}
\subsection{Selection Sort}
Selection sort puts an array in an order using nested loops. The idea is to
iterate through the array and each time find the minimal value from that index to the end index.
After the minimal element is found, swap it with the current index. This algorithm works in quadratic time
because each the upper loop will have to carry out an inner loop relative to the size of the array.
Even though the inner loop decreases in iterations as the sort progresses, this is still quadratic time because
the number of the inner iterations depends on the size of the input; thus n * n comparisons (when n is size of the array),
even if there are other constant factors. 
\lstinputlisting[linerange={247-264}, firstnumber=247]{main.cpp}
\subsection{Insertion Sort}
Insertion sort utilizes an adaptive approach with nested loops. The idea is to
iterate through the array starting at the second item and move each value 
down the array until the correct previous item is found. 
This is adaptive because the second loop only continues until the a correctly positioned item is found.
The time complexity of this algorithm is difficult to calculate directly as it depends on the order the items
are in, but the worst case is that the inner loop will have to iterate all the back to the start each time.
This puts the algorithm, in its worst case, in the same situation as selection sort since both nested loops depend on the length
of the array. Thus, this sort also have quadratic time complexity.
\lstinputlisting[linerange={268-292}, firstnumber=268]{main.cpp}
\subsection{Merge Sort}
Merge sort utilizes a divide and conquer paradigm. It recursively splits the array in halves
until there are only subarrays of length 0 or 1. This guarantees that the subarrays start in a sorted
state since an array with length 0 or 1 is already in order. Now the algorithm can merge these
subarrays back together creating large and larger subarrays at each step until it has
merged the entire array together. Every divide step is constant time and there are \(log_2n \) divides because
the array is halved each time. Each divide step must also be merged back together. There are n items to
merge back together at each divide depth. Therefore, the time complexity is big oh of \(nlog_2n\). \\
\newline
The following code is an example merge function which purposefully uses more memory allocation
to allow two individual arrays to be taken as arguments and merged into one array. This
approach may be helpful when the entire array will not be able to fit in memory.
\lstinputlisting[linerange={300-335}, firstnumber=300]{main.cpp}
\pagebreak
The following code is an example recursive case for merge sort which splits the array.
Usually the subarrays would be done in the previous function but since this implementation
receives the subarrays as arguments it must be done in this step.
\lstinputlisting[linerange={338-374}, firstnumber=338]{main.cpp}
\subsection{Quick Sort}
Quick sort also utilizes a divide and conquer (at the same time) paradigm. It recursively divides the array around
a pivot value and during each partition arranges the subarrays in their correct order relative to
only the pivot (not relative to the rest of the array or the other elements in the array). Once
sufficiently small partitions (length 1-3) have been sorted the array is now sorted because
each value is relatively placed in the correct partition after each recursive call 
(ideally the correct half of the subarrays but it will often not be perfect halves).
It may be helpful to think of best case quick sort (picking true median values for pivots)
as a binary search for the correct position of the value for each element in the array.
The time complexity for quick sort is also big oh of
\(nlog_2n\) because there are a little more than \(log_2n \) partitions 
(when a decent pivot value is chosen) and n comparisons for each partition to order the element around
the pivot at each depth.\\
\newline
The following code is used to obtain the median value of three indexes. This is needed to determine
a pivot value that will not degrade the quick sort algorithm to a quadratic time complexity. Picking 
a pivot value that is either the smallest value of the partition or the largest will order the rest 
of the elements to one side of the partition which essentially only orders a single element. Thus, the
median element of three elements from the partition ensures at least one item will be on each side.
Since the three pivot candidates are psuedo random on a shuffled array, the number of comparisons
will change depending on how close the chosen pivot is to the true median of the partition.
\lstinputlisting[linerange={377-415}, firstnumber=377]{main.cpp}
The following code partitions a range of the array ordering it relative to the pivot point.
\lstinputlisting[linerange={418-441}, firstnumber=418]{main.cpp}
The following code recursively calls itself until partitions are small enough to have
fully sorted the array.
\lstinputlisting[linerange={445-455}, firstnumber=445]{main.cpp}
\hrule
\vspace{.25cm}
What type of wedding did quick sort and merge sort have?\\ 
\indent\textit{- An arranged wedding.}\\
What was their first married argument? - \textit{How to divide the cake.}
\vspace{.25cm}
\hrule

\subsection{Sort Overview}
Each sort has its own advantages for certain scenarios: selection sort has low overhead and minimal
swapping, insertion sort works great on sorted or almost sorted arrays, merge sort looks cool, and 
quick sort is simply the GOAT. In all seriousness, merge sort and quick sort are both significantly better on large arrays
because of their time complexity. Merge sort has more overhead than quick sort, but takes less comparisons. 
Most inbuilt sorting algorithms end up using a hybrid of quick sort and insertion sort.
\begin{center}
\begin{tabular}{||c c c||} 
 \hline
 Type of Sort & Time Complexity & Number of Comparisons \\ [0.5ex] 
 \hline\hline
 Selection Sort & \( O(n^2)\) & \(221,445\) \\
 \hline
 Insertion Sort & \( O(n^2)\) & \(109,540^*\) \\
 \hline
 Merge Sort & \( O(nlog_2n)\) & \(5,399\) \\
 \hline
 Quick Sort & \( O(nlog_2n)\) & \(6,348^*\) \\
 \hline
\end{tabular}
\\
\(^*\)denotes adaptive comparison number
\end{center}
The above chart is counting the number of comparisons when sorting an array of
length 666. Although data about comparisons counted with differently ordered starting arrays
and different length arrays could lead to more comprehension conclusions, this data shows
each sort's number of comparison is proportional to its time complexity by some constant factor.
Of course, adaptive comparison numbers will change depending on the starting array; still,
their comparisons average out to be some proportional value.


\end{document}